{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad2d54e-b03e-480f-a212-b6e6b78bf6ee",
   "metadata": {},
   "source": [
    "## Evaluation of methods using gold standard corpus (see 1_sentiment_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d916f-a148-4e48-910b-07b200543988",
   "metadata": {},
   "source": [
    "In this notebook, the methods will be evaluated sing the gold standard corpora created by three annotators for polarity and emotion analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86993b5e-4409-4af9-8d23-44c916fe2407",
   "metadata": {},
   "source": [
    "### Including metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fcfe48f-52e9-496d-8de1-766248ad9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc9087b-73a5-416c-9ea7-7beae792652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "information = pd.read_csv('input/survey.txt', delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a5a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>narrative_form</th>\n",
       "      <th>periodical_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2</td>\n",
       "      <td>??</td>\n",
       "      <td>1761-07-08_El-Duende-especulativo-sobre-la-vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3</td>\n",
       "      <td>??</td>\n",
       "      <td>1761-07-27_El-Duende-especulativo-sobre-la-vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4</td>\n",
       "      <td>??</td>\n",
       "      <td>1761-09-05_El-Duende-especulativo-sobre-la-vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q5</td>\n",
       "      <td>??</td>\n",
       "      <td>1761-09-26_El-Duende-especulativo-sobre-la-vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q6</td>\n",
       "      <td>??</td>\n",
       "      <td>1761-07-27_El-Duende-especulativo-sobre-la-vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q50</td>\n",
       "      <td>D</td>\n",
       "      <td>1786_El-Juzgado-Casero_Anónimo_Vol-1_Nr-01_47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q51</td>\n",
       "      <td>FP</td>\n",
       "      <td>1786_El-Juzgado-Casero_Anónimo_Vol-1_Nr-01_47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q7</td>\n",
       "      <td>??</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q8</td>\n",
       "      <td>??</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q52</td>\n",
       "      <td>D</td>\n",
       "      <td>1787-1788_El-Duende-de-Madrid_Pedro-Pablo-Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q53</td>\n",
       "      <td>SP</td>\n",
       "      <td>1787_El-Censor_Anonym-(García-de-Cañuelo-Luis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q9</td>\n",
       "      <td>LB</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q54</td>\n",
       "      <td>EX</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q10</td>\n",
       "      <td>FP</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q55</td>\n",
       "      <td>EX</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q11</td>\n",
       "      <td>FP</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q12</td>\n",
       "      <td>??</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q13</td>\n",
       "      <td>MT</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q14</td>\n",
       "      <td>SP</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q56</td>\n",
       "      <td>S</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Q57</td>\n",
       "      <td>S</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q15</td>\n",
       "      <td>D</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q16</td>\n",
       "      <td>D</td>\n",
       "      <td>1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q58</td>\n",
       "      <td>EX</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q59</td>\n",
       "      <td>FP</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q60</td>\n",
       "      <td>S</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q17</td>\n",
       "      <td>EX</td>\n",
       "      <td>1763_La-Pensadora-Gaditana_Beatriz-Cienfuegos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q61</td>\n",
       "      <td>TR</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-2_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q62</td>\n",
       "      <td>TR</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-2_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q18</td>\n",
       "      <td>FP</td>\n",
       "      <td>1763_La-Pensadora-Gaditana_Beatriz-Cienfuegos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Q63</td>\n",
       "      <td>MT</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-2_Nr-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q64</td>\n",
       "      <td>LB</td>\n",
       "      <td>1800_El-Catón-Compostelano_Anónimo-(Francisco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Q65</td>\n",
       "      <td>LB</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q119</td>\n",
       "      <td>FP</td>\n",
       "      <td>67_El-Pensador_Joseph-Álvarez-y-Valladares-(J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q20</td>\n",
       "      <td>SP</td>\n",
       "      <td>67_El-Pensador_Joseph-Álvarez-y-Valladares-(J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Q66</td>\n",
       "      <td>LB</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q21</td>\n",
       "      <td>??</td>\n",
       "      <td>1779-1780_El-Curioso-Entretenido_Juan-Nosip-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Q67</td>\n",
       "      <td>MT</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Q68</td>\n",
       "      <td>TR</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q69</td>\n",
       "      <td>MT</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>70</td>\n",
       "      <td>LB</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Q71</td>\n",
       "      <td>FP</td>\n",
       "      <td>1803_El-Regañón-general_Anónimo-(Ventura-Ferr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Q23</td>\n",
       "      <td>FP</td>\n",
       "      <td>1779-1780_El-Curioso-Entretenido_Juan-Nosip-y-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Q24</td>\n",
       "      <td>LB</td>\n",
       "      <td>1779_El-Curioso-Entretenido_Juan-Nosip-y-Varga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Q25</td>\n",
       "      <td>FP</td>\n",
       "      <td>1780_El-Curioso-Entretenido_Juan-Nosip-y-Varga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Q26</td>\n",
       "      <td>FP</td>\n",
       "      <td>1780_El-Curioso-Entretenido_Juan-Nosip-y-Varga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Q27</td>\n",
       "      <td>F</td>\n",
       "      <td>1781_El-Censor_Anonym-(García-de-Cañuelo-Luis+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Q28</td>\n",
       "      <td>S</td>\n",
       "      <td>1781_El-Censor_Anonym-(García-de-Cañuelo-Luis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_code narrative_form  \\\n",
       "0             Q2             ??   \n",
       "1             Q3             ??   \n",
       "2             Q4             ??   \n",
       "3             Q5             ??   \n",
       "4             Q6             ??   \n",
       "5            Q50              D   \n",
       "6            Q51             FP   \n",
       "7             Q7             ??   \n",
       "8             Q8             ??   \n",
       "9            Q52              D   \n",
       "10           Q53             SP   \n",
       "11            Q9             LB   \n",
       "12           Q54             EX   \n",
       "13           Q10             FP   \n",
       "14           Q55             EX   \n",
       "15           Q11             FP   \n",
       "16           Q12             ??   \n",
       "17           Q13             MT   \n",
       "18           Q14             SP   \n",
       "19           Q56              S   \n",
       "20           Q57              S   \n",
       "21           Q15              D   \n",
       "22           Q16              D   \n",
       "23           Q58             EX   \n",
       "24           Q59             FP   \n",
       "25           Q60              S   \n",
       "26           Q17             EX   \n",
       "27           Q61             TR   \n",
       "28           Q62             TR   \n",
       "29           Q18             FP   \n",
       "30           Q63             MT   \n",
       "31           Q64             LB   \n",
       "32           Q65             LB   \n",
       "33          Q119             FP   \n",
       "34           Q20             SP   \n",
       "35           Q66             LB   \n",
       "36           Q21             ??   \n",
       "37           Q67             MT   \n",
       "38           Q68             TR   \n",
       "39           Q69             MT   \n",
       "40            70             LB   \n",
       "41           Q71             FP   \n",
       "42           Q23             FP   \n",
       "43           Q24             LB   \n",
       "44           Q25             FP   \n",
       "45           Q26             FP   \n",
       "46           Q27              F   \n",
       "47           Q28              S   \n",
       "\n",
       "                                      periodical_name  \n",
       "0   1761-07-08_El-Duende-especulativo-sobre-la-vid...  \n",
       "1   1761-07-27_El-Duende-especulativo-sobre-la-vid...  \n",
       "2   1761-09-05_El-Duende-especulativo-sobre-la-vid...  \n",
       "3    1761-09-26_El-Duende-especulativo-sobre-la-vi...  \n",
       "4   1761-07-27_El-Duende-especulativo-sobre-la-vid...  \n",
       "5    1786_El-Juzgado-Casero_Anónimo_Vol-1_Nr-01_47...  \n",
       "6    1786_El-Juzgado-Casero_Anónimo_Vol-1_Nr-01_47...  \n",
       "7    1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "8   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallada...  \n",
       "9    1787-1788_El-Duende-de-Madrid_Pedro-Pablo-Tru...  \n",
       "10   1787_El-Censor_Anonym-(García-de-Cañuelo-Luis...  \n",
       "11   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "12   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "13   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "14   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "15  1762-1763_El-Pensador_Joseph-Álvarez-y-Vallada...  \n",
       "16   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "17   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "18   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "19   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "20   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "21   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "22   1762-1763_El-Pensador_Joseph-Álvarez-y-Vallad...  \n",
       "23   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "24   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "25   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-0...  \n",
       "26   1763_La-Pensadora-Gaditana_Beatriz-Cienfuegos...  \n",
       "27   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-2_Nr-0...  \n",
       "28   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-2_Nr-0...  \n",
       "29   1763_La-Pensadora-Gaditana_Beatriz-Cienfuegos...  \n",
       "30   1788_El-Filósofo-á-la-Moda_Anónimo_Vol-2_Nr-0...  \n",
       "31   1800_El-Catón-Compostelano_Anónimo-(Francisco...  \n",
       "32   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "33   67_El-Pensador_Joseph-Álvarez-y-Valladares-(J...  \n",
       "34   67_El-Pensador_Joseph-Álvarez-y-Valladares-(J...  \n",
       "35   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "36   1779-1780_El-Curioso-Entretenido_Juan-Nosip-y...  \n",
       "37   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "38   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "39   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "40   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "41   1803_El-Regañón-general_Anónimo-(Ventura-Ferr...  \n",
       "42  1779-1780_El-Curioso-Entretenido_Juan-Nosip-y-...  \n",
       "43  1779_El-Curioso-Entretenido_Juan-Nosip-y-Varga...  \n",
       "44  1780_El-Curioso-Entretenido_Juan-Nosip-y-Varga...  \n",
       "45  1780_El-Curioso-Entretenido_Juan-Nosip-y-Varga...  \n",
       "46  1781_El-Censor_Anonym-(García-de-Cañuelo-Luis+...  \n",
       "47   1781_El-Censor_Anonym-(García-de-Cañuelo-Luis...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information.columns = ['question_code', 'narrative_form','periodical_name']\n",
    "information.columns = ['question_code', 'narrative_form','periodical_name']\n",
    "information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9929d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "information['question_code'] = information['question_code'].str.strip()\n",
    "information['narrative_form'] = information['narrative_form'].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac94e5f-628d-4a9f-909c-99ea695ae171",
   "metadata": {},
   "source": [
    "### Polarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a979dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q01</td>\n",
       "      <td>Mi pobre Vecino, posseìdo de una furiosa frene...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q50</td>\n",
       "      <td>Tiene algunos intervalos de juicio; pero luego...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>G00Q260</td>\n",
       "      <td>El teatro, decía yo, que deberia ser la escuel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>G00Q261</td>\n",
       "      <td>A buen seguro que no es ningun media cuchara, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>G00Q264</td>\n",
       "      <td>Quémense pues al momento; pero entonces fuera ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q01  Mi pobre Vecino, posseìdo de una furiosa frene...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "3          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "4          G01Q50  Tiene algunos intervalos de juicio; pero luego...   \n",
       "..            ...                                                ...   \n",
       "116       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
       "117       G00Q261  A buen seguro que no es ningun media cuchara, ...   \n",
       "118       G00Q264  Quémense pues al momento; pero entonces fuera ...   \n",
       "119       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "120       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    annotation  \n",
       "0     negative  \n",
       "1     negative  \n",
       "2     positive  \n",
       "3     negative  \n",
       "4     negative  \n",
       "..         ...  \n",
       "116   negative  \n",
       "117   positive  \n",
       "118   negative  \n",
       "119   negative  \n",
       "120   positive  \n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_polarity = pd.read_csv('input/gold_standard_corpus/3_annotators/gold_polarities.csv', delimiter=',', encoding='latin-1')\n",
    "gold_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdd996",
   "metadata": {},
   "source": [
    "# Pysentimiento (polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fad46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d249571",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = create_analyzer (task='sentiment', lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b8308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['sentence'] = gold_polarity['sentence'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1114a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005961570ac04bfe807b8e7165c88b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gold_polarity['nf_sentiment_pysentimiento'] = analyzer.predict(gold_polarity['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b0c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q01</td>\n",
       "      <td>Mi pobre Vecino, posseìdo de una furiosa frene...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.965,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.750,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q50</td>\n",
       "      <td>Tiene algunos intervalos de juicio; pero luego...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.690,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>G00Q260</td>\n",
       "      <td>El teatro, decía yo, que deberia ser la escuel...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.905,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>G00Q261</td>\n",
       "      <td>A buen seguro que no es ningun media cuchara, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.723,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>G00Q264</td>\n",
       "      <td>Quémense pues al momento; pero entonces fuera ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.777,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q01  Mi pobre Vecino, posseìdo de una furiosa frene...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "3          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "4          G01Q50  Tiene algunos intervalos de juicio; pero luego...   \n",
       "..            ...                                                ...   \n",
       "116       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
       "117       G00Q261  A buen seguro que no es ningun media cuchara, ...   \n",
       "118       G00Q264  Quémense pues al momento; pero entonces fuera ...   \n",
       "119       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "120       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    annotation                         nf_sentiment_pysentimiento  \n",
       "0     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.965,...  \n",
       "1     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.922,...  \n",
       "2     positive  AnalyzerOutput(output=POS, probas={POS: 0.922,...  \n",
       "3     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.750,...  \n",
       "4     negative  AnalyzerOutput(output=NEU, probas={NEU: 0.690,...  \n",
       "..         ...                                                ...  \n",
       "116   negative  AnalyzerOutput(output=NEG, probas={NEG: 0.905,...  \n",
       "117   positive  AnalyzerOutput(output=NEU, probas={NEU: 0.723,...  \n",
       "118   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.777,...  \n",
       "119   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...  \n",
       "120   positive  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...  \n",
       "\n",
       "[121 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d6d0c",
   "metadata": {},
   "source": [
    "# Polarity dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da9449ce-9295-4524-a093-08927a375ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c7a9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"spanish\"\n",
    "\n",
    "dictionary_dir = \"input/dictionaries/manual/\"\n",
    "dictionaryCorr = \"input/dictionaries/computational_corrected/\"\n",
    "dictionaryComp = \"input/dictionaries/computational/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b06dc3",
   "metadata": {},
   "source": [
    "### Manually made polarity dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6ebac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 798 negative words\n",
      "loaded 681 positive words\n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(dictionary_dir, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(dictionary_dir, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28120a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    num_negative = 0\n",
    "    num_positive = 0\n",
    "    for nw in sentiment_dict[\"neg\"]:\n",
    "        num_negative += tokens.count(nw.lower())\n",
    "    for pw in sentiment_dict[\"pos\"]:\n",
    "        num_positive += tokens.count(pw.lower())\n",
    "    try:\n",
    "        sentiment_score = (num_positive - num_negative) / (num_positive + num_negative)\n",
    "    except ZeroDivisionError:\n",
    "        sentiment_score = 0\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fb087d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 121/121 [00:00<00:00, 1265.34it/s]\n"
     ]
    }
   ],
   "source": [
    "gold_polarity[\"nf_sentiment_lexicon_dispecs\"] = gold_polarity[\"sentence\"].progress_apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850eea0",
   "metadata": {},
   "source": [
    "### Computationally generated dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19c0acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 691 negative words\n",
      "loaded 1034 positive words\n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(dictionaryComp, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(dictionaryComp, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a50343f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 121/121 [00:00<00:00, 1072.89it/s]\n"
     ]
    }
   ],
   "source": [
    "gold_polarity[\"nf_sentiment_lexicon_computational\"] = gold_polarity[\"sentence\"].progress_apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472ee6b",
   "metadata": {},
   "source": [
    "### Computationally generated and manually corrected dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "379c2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 812 negative words\n",
      "loaded 692 positive words\n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(dictionaryCorr, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(dictionaryCorr, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da4305b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 121/121 [00:00<00:00, 1424.26it/s]\n"
     ]
    }
   ],
   "source": [
    "gold_polarity[\"nf_sentiment_lexicon_corrected\"] = gold_polarity[\"sentence\"].progress_apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8446ca",
   "metadata": {},
   "source": [
    "# Making nicer columns (please make sure how to run) - change column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9a38918b-f10f-4d47-9023-1e87cba53c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('sentences_sentiment_emotion.pk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d8f5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_values(row):\n",
    "        if row == 0.000000 :    \n",
    "            return 'NEU'\n",
    "        elif row > 0.000000:  \n",
    "            return 'POS'\n",
    "        elif row < 0.000000:  \n",
    "            return 'NEG'\n",
    "        else:          \n",
    "            return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa19217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['manual_lexicon_sent_score'] = gold_polarity['nf_sentiment_lexicon_dispecs'].apply(change_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb13a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['comp_lexicon_sent_score'] = gold_polarity['nf_sentiment_lexicon_computational'].apply(change_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47f68043",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['corr_lexicon_sent_score'] = gold_polarity['nf_sentiment_lexicon_corrected'].apply(change_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5631c7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q01</td>\n",
       "      <td>Mi pobre Vecino, posseìdo de una furiosa frene...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.965,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.750,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q50</td>\n",
       "      <td>Tiene algunos intervalos de juicio; pero luego...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.690,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>G00Q260</td>\n",
       "      <td>El teatro, decía yo, que deberia ser la escuel...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.905,...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>G00Q261</td>\n",
       "      <td>A buen seguro que no es ningun media cuchara, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.723,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>G00Q264</td>\n",
       "      <td>Quémense pues al momento; pero entonces fuera ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.777,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q01  Mi pobre Vecino, posseìdo de una furiosa frene...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "3          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "4          G01Q50  Tiene algunos intervalos de juicio; pero luego...   \n",
       "..            ...                                                ...   \n",
       "116       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
       "117       G00Q261  A buen seguro que no es ningun media cuchara, ...   \n",
       "118       G00Q264  Quémense pues al momento; pero entonces fuera ...   \n",
       "119       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "120       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    annotation                         nf_sentiment_pysentimiento  \\\n",
       "0     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.965,...   \n",
       "1     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2     positive  AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "3     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.750,...   \n",
       "4     negative  AnalyzerOutput(output=NEU, probas={NEU: 0.690,...   \n",
       "..         ...                                                ...   \n",
       "116   negative  AnalyzerOutput(output=NEG, probas={NEG: 0.905,...   \n",
       "117   positive  AnalyzerOutput(output=NEU, probas={NEU: 0.723,...   \n",
       "118   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.777,...   \n",
       "119   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "120   positive  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            0.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.714286                            0.714286   \n",
       "3                        0.000000                            0.000000   \n",
       "4                        1.000000                            1.000000   \n",
       "..                            ...                                 ...   \n",
       "116                      0.333333                            0.333333   \n",
       "117                      1.000000                            1.000000   \n",
       "118                      1.000000                            1.000000   \n",
       "119                      0.000000                            0.000000   \n",
       "120                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected manual_lexicon_sent_score  \\\n",
       "0                          1.000000                       POS   \n",
       "1                          0.000000                       NEU   \n",
       "2                          0.714286                       POS   \n",
       "3                          0.000000                       NEU   \n",
       "4                          1.000000                       POS   \n",
       "..                              ...                       ...   \n",
       "116                        0.333333                       POS   \n",
       "117                        1.000000                       POS   \n",
       "118                        1.000000                       POS   \n",
       "119                        0.000000                       NEU   \n",
       "120                        1.000000                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score  \n",
       "0                       NEU                     POS  \n",
       "1                       NEU                     NEU  \n",
       "2                       POS                     POS  \n",
       "3                       NEU                     NEU  \n",
       "4                       POS                     POS  \n",
       "..                      ...                     ...  \n",
       "116                     POS                     POS  \n",
       "117                     POS                     POS  \n",
       "118                     POS                     POS  \n",
       "119                     NEU                     NEU  \n",
       "120                     POS                     POS  \n",
       "\n",
       "[121 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6361f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['nf_sentiment_pysentimiento'] = gold_polarity['nf_sentiment_pysentimiento'].astype('string')\n",
    "gold_polarity['sentiment_py'] = gold_polarity['nf_sentiment_pysentimiento'].str.findall(r'\\=([^,]+)\\, probas')\n",
    "gold_polarity['sentiment_py'] = gold_polarity['sentiment_py'].astype('string')\n",
    "gold_polarity['sentiment_py'] = gold_polarity['sentiment_py'].str.replace('[', '')\n",
    "gold_polarity['sentiment_py'] = gold_polarity['sentiment_py'].str.replace(']', '')\n",
    "gold_polarity['sentiment_py'] = gold_polarity['sentiment_py'].str.replace(\"'\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "765e61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "      <th>sentiment_py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q01</td>\n",
       "      <td>Mi pobre Vecino, posseìdo de una furiosa frene...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.965,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.750,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q50</td>\n",
       "      <td>Tiene algunos intervalos de juicio; pero luego...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.690,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>G00Q260</td>\n",
       "      <td>El teatro, decía yo, que deberia ser la escuel...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.905,...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>G00Q261</td>\n",
       "      <td>A buen seguro que no es ningun media cuchara, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.723,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>G00Q264</td>\n",
       "      <td>Quémense pues al momento; pero entonces fuera ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.777,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q01  Mi pobre Vecino, posseìdo de una furiosa frene...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "3          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "4          G01Q50  Tiene algunos intervalos de juicio; pero luego...   \n",
       "..            ...                                                ...   \n",
       "116       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
       "117       G00Q261  A buen seguro que no es ningun media cuchara, ...   \n",
       "118       G00Q264  Quémense pues al momento; pero entonces fuera ...   \n",
       "119       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "120       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    annotation                         nf_sentiment_pysentimiento  \\\n",
       "0     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.965,...   \n",
       "1     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2     positive  AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "3     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.750,...   \n",
       "4     negative  AnalyzerOutput(output=NEU, probas={NEU: 0.690,...   \n",
       "..         ...                                                ...   \n",
       "116   negative  AnalyzerOutput(output=NEG, probas={NEG: 0.905,...   \n",
       "117   positive  AnalyzerOutput(output=NEU, probas={NEU: 0.723,...   \n",
       "118   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.777,...   \n",
       "119   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "120   positive  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            0.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.714286                            0.714286   \n",
       "3                        0.000000                            0.000000   \n",
       "4                        1.000000                            1.000000   \n",
       "..                            ...                                 ...   \n",
       "116                      0.333333                            0.333333   \n",
       "117                      1.000000                            1.000000   \n",
       "118                      1.000000                            1.000000   \n",
       "119                      0.000000                            0.000000   \n",
       "120                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected manual_lexicon_sent_score  \\\n",
       "0                          1.000000                       POS   \n",
       "1                          0.000000                       NEU   \n",
       "2                          0.714286                       POS   \n",
       "3                          0.000000                       NEU   \n",
       "4                          1.000000                       POS   \n",
       "..                              ...                       ...   \n",
       "116                        0.333333                       POS   \n",
       "117                        1.000000                       POS   \n",
       "118                        1.000000                       POS   \n",
       "119                        0.000000                       NEU   \n",
       "120                        1.000000                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score sentiment_py  \n",
       "0                       NEU                     POS          NEG  \n",
       "1                       NEU                     NEU          NEG  \n",
       "2                       POS                     POS          POS  \n",
       "3                       NEU                     NEU          NEG  \n",
       "4                       POS                     POS          NEU  \n",
       "..                      ...                     ...          ...  \n",
       "116                     POS                     POS          NEG  \n",
       "117                     POS                     POS          NEU  \n",
       "118                     POS                     POS          NEU  \n",
       "119                     NEU                     NEU          NEU  \n",
       "120                     POS                     POS          NEG  \n",
       "\n",
       "[121 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b63c58",
   "metadata": {},
   "source": [
    "# Calculating accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61409c87",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5c9ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b64979d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['sentiment_annotation_list'] = gold_polarity['annotation'].replace(['positive','negative','neutral'],['1','3','2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6daf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['sentiment_py_list'] = gold_polarity['sentiment_py'].replace(['POS','NEG','NEU'],['1','3','2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4965ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['corr_lexicon_sent_score_list'] = gold_polarity['corr_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c080c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_polarity['manual_lexicon_sent_score_list'] = gold_polarity['manual_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a637a3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "      <th>sentiment_py</th>\n",
       "      <th>sentiment_annotation_list</th>\n",
       "      <th>sentiment_py_list</th>\n",
       "      <th>corr_lexicon_sent_score_list</th>\n",
       "      <th>manual_lexicon_sent_score_list</th>\n",
       "      <th>computational_lexicon_sent_score_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q01</td>\n",
       "      <td>Mi pobre Vecino, posseìdo de una furiosa frene...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.965,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.750,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q50</td>\n",
       "      <td>Tiene algunos intervalos de juicio; pero luego...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.690,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>G00Q260</td>\n",
       "      <td>El teatro, decía yo, que deberia ser la escuel...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.905,...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>G00Q261</td>\n",
       "      <td>A buen seguro que no es ningun media cuchara, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.723,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>G00Q264</td>\n",
       "      <td>Quémense pues al momento; pero entonces fuera ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.777,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>negative</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q01  Mi pobre Vecino, posseìdo de una furiosa frene...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "3          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "4          G01Q50  Tiene algunos intervalos de juicio; pero luego...   \n",
       "..            ...                                                ...   \n",
       "116       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
       "117       G00Q261  A buen seguro que no es ningun media cuchara, ...   \n",
       "118       G00Q264  Quémense pues al momento; pero entonces fuera ...   \n",
       "119       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "120       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    annotation                         nf_sentiment_pysentimiento  \\\n",
       "0     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.965,...   \n",
       "1     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2     positive  AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "3     negative  AnalyzerOutput(output=NEG, probas={NEG: 0.750,...   \n",
       "4     negative  AnalyzerOutput(output=NEU, probas={NEU: 0.690,...   \n",
       "..         ...                                                ...   \n",
       "116   negative  AnalyzerOutput(output=NEG, probas={NEG: 0.905,...   \n",
       "117   positive  AnalyzerOutput(output=NEU, probas={NEU: 0.723,...   \n",
       "118   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.777,...   \n",
       "119   negative  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "120   positive  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            0.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.714286                            0.714286   \n",
       "3                        0.000000                            0.000000   \n",
       "4                        1.000000                            1.000000   \n",
       "..                            ...                                 ...   \n",
       "116                      0.333333                            0.333333   \n",
       "117                      1.000000                            1.000000   \n",
       "118                      1.000000                            1.000000   \n",
       "119                      0.000000                            0.000000   \n",
       "120                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected manual_lexicon_sent_score  \\\n",
       "0                          1.000000                       POS   \n",
       "1                          0.000000                       NEU   \n",
       "2                          0.714286                       POS   \n",
       "3                          0.000000                       NEU   \n",
       "4                          1.000000                       POS   \n",
       "..                              ...                       ...   \n",
       "116                        0.333333                       POS   \n",
       "117                        1.000000                       POS   \n",
       "118                        1.000000                       POS   \n",
       "119                        0.000000                       NEU   \n",
       "120                        1.000000                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score sentiment_py  \\\n",
       "0                       NEU                     POS          NEG   \n",
       "1                       NEU                     NEU          NEG   \n",
       "2                       POS                     POS          POS   \n",
       "3                       NEU                     NEU          NEG   \n",
       "4                       POS                     POS          NEU   \n",
       "..                      ...                     ...          ...   \n",
       "116                     POS                     POS          NEG   \n",
       "117                     POS                     POS          NEU   \n",
       "118                     POS                     POS          NEU   \n",
       "119                     NEU                     NEU          NEU   \n",
       "120                     POS                     POS          NEG   \n",
       "\n",
       "    sentiment_annotation_list sentiment_py_list corr_lexicon_sent_score_list  \\\n",
       "0                    negative                 3                            1   \n",
       "1                    negative                 3                            2   \n",
       "2                    positive                 1                            1   \n",
       "3                    negative                 3                            2   \n",
       "4                    negative                 2                            1   \n",
       "..                        ...               ...                          ...   \n",
       "116                  negative                 3                            1   \n",
       "117                  positive                 2                            1   \n",
       "118                  negative                 2                            1   \n",
       "119                  negative                 2                            2   \n",
       "120                  positive                 3                            1   \n",
       "\n",
       "    manual_lexicon_sent_score_list computational_lexicon_sent_score_list  \n",
       "0                                1                                     2  \n",
       "1                                2                                     2  \n",
       "2                                1                                     1  \n",
       "3                                2                                     2  \n",
       "4                                1                                     1  \n",
       "..                             ...                                   ...  \n",
       "116                              1                                     1  \n",
       "117                              1                                     1  \n",
       "118                              1                                     1  \n",
       "119                              2                                     2  \n",
       "120                              1                                     1  \n",
       "\n",
       "[121 rows x 16 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_polarity['computational_lexicon_sent_score_list'] = gold_polarity['comp_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n",
    "gold_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e2920e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c867a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '3', '1', '3', '3', '3', '3', '3', '3', '1', '3', '3', '1', '3', '1', '1', '3', '3', '1', '1', '3', '1', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '1', '3', '3', '2', '3', '3', '3', '3', '3', '1', '1', '3', '3', '1', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '1', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '1', '3', '3', '1', '1', '1', '3', '1', '3', '3', '1']\n"
     ]
    }
   ],
   "source": [
    "sentiment_annotation_list = gold_polarity['sentiment_annotation_list'].tolist()\n",
    "print(sentiment_annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd4f360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '3', '1', '3', '2', '3', '3', '3', '3', '3', '3', '3', '1', '3', '2', '1', '3', '3', '1', '1', '3', '3', '3', '3', '3', '3', '2', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '2', '3', '2', '3', '3', '3', '2', '3', '3', '3', '2', '3', '1', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '1', '3', '1', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '1', '2', '3', '1', '1', '2', '3', '2', '2', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "sentiment_py_list = gold_polarity['sentiment_py_list'].tolist()\n",
    "print(sentiment_py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70e0ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '1', '2', '1', '1', '2', '2', '3', '3', '1', '2', '1', '3', '2', '1', '3', '1', '1', '1', '1', '2', '3', '3', '3', '1', '1', '3', '1', '3', '3', '2', '3', '3', '1', '3', '3', '3', '1', '1', '1', '1', '3', '2', '2', '3', '2', '3', '1', '2', '2', '3', '3', '2', '1', '3', '3', '2', '2', '3', '3', '3', '3', '3', '1', '1', '1', '1', '3', '1', '2', '2', '3', '3', '3', '3', '1', '3', '1', '2', '3', '3', '3', '1', '1', '3', '2', '1', '1', '1', '3', '1', '1', '1', '3', '2', '2', '2', '2', '3', '1', '3', '3', '3', '3', '2', '2', '3', '3', '1', '1', '3', '1', '1', '1', '1', '1', '1', '1', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "corr_lexicon_sent_score_list = df_sentiment['corr_lexicon_sent_score_list'].tolist()\n",
    "print(corr_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ddf228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '1', '2', '1', '1', '2', '2', '3', '3', '1', '2', '1', '3', '2', '1', '3', '1', '1', '1', '1', '2', '3', '3', '3', '1', '1', '3', '1', '3', '3', '2', '3', '3', '1', '3', '3', '3', '1', '1', '1', '1', '3', '2', '2', '3', '2', '3', '1', '2', '2', '3', '3', '2', '1', '3', '3', '2', '2', '3', '3', '3', '3', '3', '1', '1', '1', '1', '3', '1', '2', '2', '3', '3', '3', '3', '1', '3', '1', '2', '3', '3', '3', '1', '1', '3', '2', '1', '1', '1', '3', '1', '1', '1', '3', '2', '2', '2', '2', '3', '1', '3', '3', '3', '3', '2', '2', '3', '3', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "manual_lexicon_sent_score_list = df_sentiment['manual_lexicon_sent_score_list'].tolist()\n",
    "print(manual_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dee72c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '2', '1', '2', '1', '2', '2', '2', '3', '3', '1', '2', '1', '3', '1', '1', '3', '1', '1', '1', '1', '2', '3', '3', '3', '1', '1', '3', '1', '3', '3', '2', '3', '2', '1', '3', '3', '3', '1', '1', '1', '1', '3', '1', '2', '3', '2', '3', '1', '3', '1', '3', '3', '2', '1', '1', '3', '2', '2', '3', '3', '3', '3', '2', '1', '1', '1', '2', '2', '1', '2', '2', '3', '3', '3', '3', '1', '1', '1', '2', '3', '3', '3', '2', '1', '3', '2', '1', '1', '1', '3', '2', '1', '1', '3', '1', '2', '2', '2', '3', '1', '3', '3', '2', '1', '1', '2', '3', '3', '1', '1', '3', '1', '1', '1', '1', '1', '1', '1', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "computational_lexicon_sent_score_list = df_sentiment['computational_lexicon_sent_score_list'].tolist()\n",
    "print(computational_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1bf83",
   "metadata": {},
   "source": [
    "## Pysentimiento sentiment accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2847f011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7933884297520661"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,sentiment_py_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f526e",
   "metadata": {},
   "source": [
    "Pysentimiento has ok accuracy - 60% - https://stephenallwright.com/good-accuracy-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6c8c573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,sentiment_py_list, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d978c351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.52      0.67        27\n",
      "           2       0.06      0.33      0.11         3\n",
      "           3       0.90      0.89      0.90        91\n",
      "\n",
      "    accuracy                           0.79       121\n",
      "   macro avg       0.63      0.58      0.56       121\n",
      "weighted avg       0.89      0.79      0.82       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(sentiment_annotation_list, sentiment_py_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d3e7e",
   "metadata": {},
   "source": [
    "Recall: out of all the sentences that the model predicted, 76% match the test set. F1 shows that the model did a OK job (77%) of predicting the sentiment. Precision - measure how many of the positive predictions made are correct, recall - how many of the positive cases the classifier correctly predicred over all the pos cases - https://www.statology.org/sklearn-classification-report/, https://stephenallwright.com/interpret-f1-score/, https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c9f90a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  6,  7],\n",
       "       [ 0,  1,  2],\n",
       "       [ 1,  9, 81]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_pysentimiento = confusion_matrix(sentiment_annotation_list, sentiment_py_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec92be-6774-4fe4-b57f-060daadbf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_pysentimiento, annot=True, fmt='d', cmap='Blues', xticklabels=['Positive', 'Negative', 'Neutral'], yticklabels=['Positive', 'Negative', 'Neutral'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix1.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7ff41",
   "metadata": {},
   "source": [
    "## Corrected lexicon sentiment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "512e12dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5041322314049587"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,corr_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6e860f0-5afd-4997-adb2-aa195cab8aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.67      0.49        27\n",
      "           2       0.04      0.33      0.06         3\n",
      "           3       0.89      0.45      0.60        91\n",
      "\n",
      "    accuracy                           0.50       121\n",
      "   macro avg       0.44      0.48      0.38       121\n",
      "weighted avg       0.76      0.50      0.56       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_annotation_list, manual_lexicon_sent_score_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12954d",
   "metadata": {},
   "source": [
    "# Manual lexicon sentiment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9e4d83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49586776859504134"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,manual_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70f1324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.67      0.49        27\n",
      "           2       0.04      0.33      0.06         3\n",
      "           3       0.89      0.45      0.60        91\n",
      "\n",
      "    accuracy                           0.50       121\n",
      "   macro avg       0.44      0.48      0.38       121\n",
      "weighted avg       0.76      0.50      0.56       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_annotation_list, manual_lexicon_sent_score_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c32fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(sentiment_annotation_list, manual_lexicon_sent_score_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce193eb0",
   "metadata": {},
   "source": [
    "## Computational lexicon sentiment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da15a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(sentiment_annotation_list,computational_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(sentiment_annotation_list, computational_lexicon_sent_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(sentiment_annotation_list, computational_lexicon_sent_score_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "49f28a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('sentences_sentiment_emotion.pk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd98393",
   "metadata": {},
   "source": [
    "# Emotion lexicon evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_annotation'] = df['emotion_annotation'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14966fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = df[df[\"emotion_annotation\"] != 'no_agreement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = df_emotion[df_emotion[\"emotion_annotation\"] != 'anticipation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = df_emotion[df_emotion[\"emotion_annotation\"] != 'trust']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed12608",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766172c",
   "metadata": {},
   "source": [
    "joy - 1\n",
    "sadness - 2\n",
    "anger - 3\n",
    "disgust - 4\n",
    "surprise - 5\n",
    "fear - 6 \n",
    "no_emotion(others) - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['emotion_annotation_list'] = df_emotion['emotion_annotation'].replace(['joy','sadness','anger','disgust','surprise','fear','no_emotion'],['1','2','3','4','5','6','7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_annotation_list = df_emotion['emotion_annotation_list'].tolist()\n",
    "print(emotion_annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['emotion_py_list'] = df_emotion['emotion_py'].replace(['joy','sadness','anger','disgust','surprise','fear','others'],['1','2','3','4','5','6','7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca14f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_py_list = df_emotion['emotion_py_list'].tolist()\n",
    "print(emotion_py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['emotion_lexicon_list'] = df_emotion['lexicon_emotion'].replace(['joy','sadness','anger','disgust','surprise','fear','others'],['1','2','3','4','5','6','7'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffebb8",
   "metadata": {},
   "source": [
    "# Emotion Lexicon accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3614557",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(emotion_annotation_list,emotion_lexicon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ed29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(emotion_annotation_list,emotion_lexicon_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69695c5",
   "metadata": {},
   "source": [
    "# Pysentimiento emotion accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(emotion_annotation_list,emotion_py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc202855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(emotion_annotation_list,emotion_py_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355e17a",
   "metadata": {},
   "source": [
    "Saving the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bbd2b72c-6ac6-4c0a-a547-52e4d34db814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('sentences_sentiment_emotion.pk')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
