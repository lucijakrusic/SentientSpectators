{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "008bffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74a5a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>narrative_form</th>\n",
       "      <th>periodical_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>LB</td>\n",
       "      <td>1761-07-08_El-Duende-especulativo-sobre-la-vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>EX</td>\n",
       "      <td>1761-09-05_El-Duende-especulativo-sobre-la-vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>TR</td>\n",
       "      <td>1761-09-05_El-Duende-especulativo-sobre-la-vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>FP</td>\n",
       "      <td>1761-09-26_El-Duende-especulativo-sobre-la-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>??</td>\n",
       "      <td>1761-07-27_El-Duende-especulativo-sobre-la-vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>MT</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>MT</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>FP</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>MT</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>LB</td>\n",
       "      <td>1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code narrative_form  \\\n",
       "0          G01Q02             LB   \n",
       "1          G01Q03            EX    \n",
       "2        G01Q04             TR     \n",
       "3          G01Q05            FP    \n",
       "4          G01Q06             ??   \n",
       "..            ...            ...   \n",
       "268       G00Q266             MT   \n",
       "269       G00Q267             MT   \n",
       "270       G00Q268             FP   \n",
       "271       G00Q269             MT   \n",
       "272       G00Q270             LB   \n",
       "\n",
       "                                       periodical_name  \n",
       "0     1761-07-08_El-Duende-especulativo-sobre-la-vi...  \n",
       "1     1761-09-05_El-Duende-especulativo-sobre-la-vi...  \n",
       "2     1761-09-05_El-Duende-especulativo-sobre-la-vi...  \n",
       "3      1761-09-26_El-Duende-especulativo-sobre-la-v...  \n",
       "4     1761-07-27_El-Duende-especulativo-sobre-la-vi...  \n",
       "..                                                 ...  \n",
       "268  1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...  \n",
       "269  1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...  \n",
       "270  1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...  \n",
       "271  1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-00...  \n",
       "272  1788_El-Filósofo-á-la-Moda_Anónimo_Vol-1_Nr-01...  \n",
       "\n",
       "[273 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information = pd.read_csv('question_nf_filename.txt', delimiter='|', encoding='utf-8')\n",
    "information.columns = ['question_code', 'narrative_form','periodical_name']\n",
    "information.columns = ['question_code', 'narrative_form','periodical_name']\n",
    "information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a9929d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "information['question_code'] = information['question_code'].str.strip()\n",
    "information['narrative_form'] = information['narrative_form'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5a979dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>G00Q132</td>\n",
       "      <td>Es un Fenix entre los hombres.</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>G00Q133</td>\n",
       "      <td>Pero todo esto es inutil, y èl ha hallado el m...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>G00Q134</td>\n",
       "      <td>Conociò su yerro, y procurò enmendarlo escribi...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>G00Q135</td>\n",
       "      <td>El modo de quedar ayrosos les es muy facil.</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q25</td>\n",
       "      <td>La fama y los ilustres contratiempos Recordará...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "130       G00Q132                     Es un Fenix entre los hombres.   \n",
       "131       G00Q133  Pero todo esto es inutil, y èl ha hallado el m...   \n",
       "132       G00Q134  Conociò su yerro, y procurò enmendarlo escribi...   \n",
       "133       G00Q135        El modo de quedar ayrosos les es muy facil.   \n",
       "134        G00Q25  La fama y los ilustres contratiempos Recordará...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \n",
       "0                    NEU       no_agreement  \n",
       "1                    NEG            disgust  \n",
       "2                    NEU      no_agreement   \n",
       "3                    POS                joy  \n",
       "4                    NEG       no_agreement  \n",
       "..                   ...                ...  \n",
       "130                  POS                joy  \n",
       "131                  NEG            disgust  \n",
       "132                  NEG            sadness  \n",
       "133                  NEG      no_agreement   \n",
       "134                  NEG      no_agreement   \n",
       "\n",
       "[135 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey1 = pd.read_csv('sentences_survey1.txt', delimiter='|', encoding='utf-8')\n",
    "survey1.columns = ['question_code', 'sentence','sentiment_annotation','emotion_annotation']\n",
    "survey1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "27f31a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G00Q137</td>\n",
       "      <td>Miralos sin humanidad, y como esclavos, y ello...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G00Q138</td>\n",
       "      <td>No es tan facil determinar por dónde se ha de ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G00Q139</td>\n",
       "      <td>Tù debes acordarte de la ternura, con que se p...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G00Q140</td>\n",
       "      <td>Alli estarà mas tranquilo, y podrà vivir à su ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G00Q141</td>\n",
       "      <td>Confiesso à Vm. que yá no puedo sufrir la vida...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0         G00Q137  Miralos sin humanidad, y como esclavos, y ello...   \n",
       "1         G00Q138  No es tan facil determinar por dónde se ha de ...   \n",
       "2         G00Q139  Tù debes acordarte de la ternura, con que se p...   \n",
       "3         G00Q140  Alli estarà mas tranquilo, y podrà vivir à su ...   \n",
       "4         G00Q141  Confiesso à Vm. que yá no puedo sufrir la vida...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \n",
       "0                    NEG       no_agreement  \n",
       "1                    NEU         no_emotion  \n",
       "2                    POS                joy  \n",
       "3                    POS       no_agreement  \n",
       "4                    NEG            sadness  \n",
       "..                   ...                ...  \n",
       "134         no_agreement       no_agreement  \n",
       "135                  NEG            disgust  \n",
       "136                  POS       no_agreement  \n",
       "137                  NEU         no_emotion  \n",
       "138                  POS       no_agreement  \n",
       "\n",
       "[139 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey2 = pd.read_csv('sentences_survey2.txt', delimiter='|', encoding='utf8',quoting=csv.QUOTE_NONE)\n",
    "survey2.columns = ['question_code', 'sentence','sentiment_annotation','emotion_annotation']\n",
    "survey2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d607e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\2456047559.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  survey = survey1.append(survey2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \n",
       "0                    NEU       no_agreement  \n",
       "1                    NEG            disgust  \n",
       "2                    NEU      no_agreement   \n",
       "3                    POS                joy  \n",
       "4                    NEG       no_agreement  \n",
       "..                   ...                ...  \n",
       "134         no_agreement       no_agreement  \n",
       "135                  NEG            disgust  \n",
       "136                  POS       no_agreement  \n",
       "137                  NEU         no_emotion  \n",
       "138                  POS       no_agreement  \n",
       "\n",
       "[274 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey = survey1.append(survey2)\n",
    "survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "16356973",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_survey1 = survey1[survey1.duplicated(subset='question_code', keep=False)]\n",
    "duplicates_survey2 = survey2[survey2.duplicated(subset='question_code', keep=False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "684ea3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in df1:\n",
      "Empty DataFrame\n",
      "Columns: [question_code, sentence, sentiment_annotation, emotion_annotation]\n",
      "Index: []\n",
      "\n",
      "Duplicates in df2:\n",
      "    question_code                                           sentence  \\\n",
      "27        G00Q164  Ni tantos ancianos, que en la mas estrecha ang...   \n",
      "28        G00Q164  Ni tantos ancianos, que en la mas estrecha ang...   \n",
      "38        G00Q174  Lucio es un ingrato, es un Hombre, que entrega...   \n",
      "39        G00Q174  Lucio es un ingrato, es un Hombre, que entrega...   \n",
      "58        G00Q186  Se vè sujeto â las trayciones, expuesto â los ...   \n",
      "59        G00Q186  Se vè sujeto â las trayciones, expuesto â los ...   \n",
      "74        G00Q216  Es un cobarde, un vil, un indigno de los honor...   \n",
      "75        G00Q216  Es un cobarde, un vil, un indigno de los honor...   \n",
      "127       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
      "128       G00Q260  El teatro, decía yo, que deberia ser la escuel...   \n",
      "\n",
      "    sentiment_annotation emotion_annotation  \n",
      "27                   NEG            disgust  \n",
      "28                   NEG            sadness  \n",
      "38                   NEG              anger  \n",
      "39                   NEG            disgust  \n",
      "58                   NEG            disgust  \n",
      "59                   NEG            sadness  \n",
      "74                   NEG              anger  \n",
      "75                   NEG            disgust  \n",
      "127                  NEG              anger  \n",
      "128                  NEG            disgust  \n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicates in df1:\")\n",
    "print(duplicates_survey1)\n",
    "\n",
    "print(\"\\nDuplicates in df2:\")\n",
    "print(duplicates_survey2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f7e8eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = survey.drop_duplicates(subset=['question_code', 'sentence'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f393cd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3544754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdd996",
   "metadata": {},
   "source": [
    "# Pysentimiento (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6fad46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5d249571",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = create_analyzer (task='sentiment', lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a5b8308e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1000395619.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentence'] = df['sentence'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "df['sentence'] = df['sentence'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1114a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344d5e08453340af884c3e2f5c0aebc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\2173828748.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nf_sentiment_pysentimiento'] = analyzer.predict(df['sentence'])\n"
     ]
    }
   ],
   "source": [
    "df['nf_sentiment_pysentimiento'] = analyzer.predict(df['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9b0c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.913,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "134         no_agreement       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...  \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...  \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...  \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...  \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...  \n",
       "..                                                 ...  \n",
       "134  AnalyzerOutput(output=NEG, probas={NEG: 0.913,...  \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...  \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...  \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...  \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...  \n",
       "\n",
       "[268 rows x 5 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3b82ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1497275347.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"sentence\"]=df[\"sentence\"]. apply(str)\n"
     ]
    }
   ],
   "source": [
    "df[\"sentence\"]=df[\"sentence\"]. apply(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba20c73",
   "metadata": {},
   "source": [
    "# Pysentimiento (emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e815395",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "82f6d8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e845ac5101274146bf9e321763d86458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3419555469.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nf_emotion_pysentimiento'] = emotion_analyzer.predict(df['sentence'])\n"
     ]
    }
   ],
   "source": [
    "df['nf_emotion_pysentimiento'] = emotion_analyzer.predict(df['sentence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d6d0c",
   "metadata": {},
   "source": [
    "# Sentiment lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9c7a9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"spanish\"\n",
    "\n",
    "dictionary_dir = \"dictionaries/manual/\"\n",
    "dictionaryCorr = \"dictionaries/computational_corrected/\"\n",
    "dictionaryComp = \"dictionaries/computational/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b06dc3",
   "metadata": {},
   "source": [
    "MAnual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6ebac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 798 negative words\n",
      "loaded 681 positive words\n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(dictionary_dir, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(dictionary_dir, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "28120a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    num_negative = 0\n",
    "    num_positive = 0\n",
    "    for nw in sentiment_dict[\"neg\"]:\n",
    "        num_negative += tokens.count(nw.lower())\n",
    "    for pw in sentiment_dict[\"pos\"]:\n",
    "        num_positive += tokens.count(pw.lower())\n",
    "    try:\n",
    "        sentiment_score = (num_positive - num_negative) / (num_positive + num_negative)\n",
    "    except ZeroDivisionError:\n",
    "        sentiment_score = 0\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7fb087d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75908e923c29438b8b50e8a689385dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1777196024.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"nf_sentiment_lexicon_dispecs\"] = df[\"sentence\"].progress_apply(compute_sentiment)\n"
     ]
    }
   ],
   "source": [
    "df[\"nf_sentiment_lexicon_dispecs\"] = df[\"sentence\"].progress_apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850eea0",
   "metadata": {},
   "source": [
    "Computational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "19c0acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 691 negative words\n",
      "loaded 1034 positive words\n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(dictionaryComp, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(dictionaryComp, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a50343f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4549f23f00904625b9022dbddafd6583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3105877916.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"nf_sentiment_lexicon_computational\"] = df[\"sentence\"].progress_apply(compute_sentiment)\n"
     ]
    }
   ],
   "source": [
    "df[\"nf_sentiment_lexicon_computational\"] = df[\"sentence\"].progress_apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472ee6b",
   "metadata": {},
   "source": [
    "Corrected dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "379c2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 812 negative words\n",
      "loaded 692 positive words\n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "with open(\"{}{}_negative.txt\".format(dictionaryCorr, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"neg\"] = fr.read().splitlines()\n",
    "with open(\"{}{}_positive.txt\".format(dictionaryCorr, language.lower()), \"r\", encoding=\"utf-8\") as fr:\n",
    "    sentiment_dict[\"pos\"] = fr.read().splitlines()\n",
    "\n",
    "print(\"loaded {} negative words\".format(len(sentiment_dict[\"neg\"])))\n",
    "print(\"loaded {} positive words\".format(len(sentiment_dict[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "da4305b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aeb08a8aea41f2ba0456727cadb7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3186268653.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"nf_sentiment_lexicon_corrected\"] = df[\"sentence\"].progress_apply(compute_sentiment)\n"
     ]
    }
   ],
   "source": [
    "df[\"nf_sentiment_lexicon_corrected\"] = df[\"sentence\"].progress_apply(compute_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1ab11",
   "metadata": {},
   "source": [
    "# Emotion lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "37fab340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 382 anger words\n",
      "loaded 209 disgust words\n",
      "loaded 668 joy words\n",
      "loaded 211 fear words\n",
      "loaded 391 sadness words\n",
      "loaded 175 surprise words\n"
     ]
    }
   ],
   "source": [
    "new_dictionary_dir = \"dictionaries/emotion/\"\n",
    "\n",
    "emotion_dict = {}\n",
    "with open(new_dictionary_dir + \"anger.txt\", \"r\", encoding=\"utf-8\") as em:\n",
    "    emotion_dict[\"anger\"] = em.read().splitlines()\n",
    "with open(new_dictionary_dir + \"disgust.txt\", \"r\", encoding=\"utf-8\") as em:\n",
    "    emotion_dict[\"disgust\"] = em.read().splitlines()\n",
    "with open(new_dictionary_dir + \"joy.txt\", \"r\", encoding=\"utf-8\") as em:\n",
    "    emotion_dict[\"joy\"] = em.read().splitlines()\n",
    "with open(new_dictionary_dir + \"fear.txt\", \"r\", encoding=\"utf-8\") as em:\n",
    "    emotion_dict[\"fear\"] = em.read().splitlines()\n",
    "with open(new_dictionary_dir + \"sadness.txt\", \"r\", encoding=\"utf-8\") as em:\n",
    "    emotion_dict[\"sadness\"] = em.read().splitlines()\n",
    "with open(new_dictionary_dir +\"surprise.txt\", \"r\", encoding=\"utf-8\") as em:\n",
    "    emotion_dict[\"surprise\"] = em.read().splitlines()\n",
    "    \n",
    "\n",
    "print(\"loaded {} anger words\".format(len(emotion_dict[\"anger\"])))\n",
    "print(\"loaded {} disgust words\".format(len(emotion_dict[\"disgust\"])))\n",
    "print(\"loaded {} joy words\".format(len(emotion_dict[\"joy\"])))\n",
    "print(\"loaded {} fear words\".format(len(emotion_dict[\"fear\"])))\n",
    "print(\"loaded {} sadness words\".format(len(emotion_dict[\"sadness\"])))\n",
    "print(\"loaded {} surprise words\".format(len(emotion_dict[\"surprise\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6a611803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_emotion(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    num_anger = 0\n",
    "    num_disgust = 0\n",
    "    num_joy = 0\n",
    "    num_fear = 0\n",
    "    num_sadness = 0\n",
    "    num_surprise = 0\n",
    "    for anger in emotion_dict[\"anger\"]:\n",
    "        num_anger += tokens.count(anger.lower())\n",
    "    for disgust in emotion_dict[\"disgust\"]:\n",
    "        num_disgust += tokens.count(disgust.lower())\n",
    "    for joy in emotion_dict[\"joy\"]:\n",
    "        num_joy += tokens.count(joy.lower())\n",
    "    for fear in emotion_dict[\"fear\"]:\n",
    "        num_fear += tokens.count(fear.lower())\n",
    "    for sadness in emotion_dict[\"sadness\"]:\n",
    "        num_sadness += tokens.count(sadness.lower())\n",
    "    for surprise in emotion_dict[\"surprise\"]:\n",
    "        num_surprise += tokens.count(surprise.lower())\n",
    "    try:\n",
    "        emotion_score = {'anger' : num_anger,'joy' : num_joy,'disgust' : num_disgust,'fear': num_fear, 'sadness': num_sadness, 'surprise':num_surprise}\n",
    "        emotion = max(emotion_score, key=emotion_score.get)\n",
    "\n",
    "    except:\n",
    "        print(\"Something went wrong\")\n",
    "    if all(value == 0 for value in emotion_score.values()):\n",
    "        return (\"others\")\n",
    "    else:\n",
    "        return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cad35eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baab67507b0d47368386b857a4a781c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3890212278.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"lexicon_emotion\"] = df[\"sentence\"].progress_apply(one_emotion)\n"
     ]
    }
   ],
   "source": [
    "df[\"lexicon_emotion\"] = df[\"sentence\"].progress_apply(one_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f725595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_emotion_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>lexicon_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "      <td>AnalyzerOutput(output=sadness, probas={sadness...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.936,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.913,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.861,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "134         no_agreement       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...   \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...   \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=NEG, probas={NEG: 0.913,...   \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...   \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...   \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "                              nf_emotion_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=others, probas={others: ...   \n",
       "1    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "2    AnalyzerOutput(output=sadness, probas={sadness...   \n",
       "3    AnalyzerOutput(output=joy, probas={joy: 0.936,...   \n",
       "4    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=others, probas={others: ...   \n",
       "135  AnalyzerOutput(output=others, probas={others: ...   \n",
       "136  AnalyzerOutput(output=joy, probas={joy: 0.861,...   \n",
       "137  AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "138  AnalyzerOutput(output=others, probas={others: ...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            1.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.000000                            0.000000   \n",
       "3                        0.714286                            0.714286   \n",
       "4                        0.000000                            0.000000   \n",
       "..                            ...                                 ...   \n",
       "134                     -1.000000                           -1.000000   \n",
       "135                      0.000000                            0.000000   \n",
       "136                      1.000000                            1.000000   \n",
       "137                      1.000000                            1.000000   \n",
       "138                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected lexicon_emotion  \n",
       "0                          1.000000             joy  \n",
       "1                          0.000000         disgust  \n",
       "2                          0.000000           anger  \n",
       "3                          0.714286             joy  \n",
       "4                          0.000000             joy  \n",
       "..                              ...             ...  \n",
       "134                       -1.000000           anger  \n",
       "135                        0.000000          others  \n",
       "136                        1.000000          others  \n",
       "137                        1.000000          others  \n",
       "138                        1.000000          others  \n",
       "\n",
       "[268 rows x 10 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8446ca",
   "metadata": {},
   "source": [
    "# Making nicer columns (please make sure how to run) - change column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7d8f5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_values(row):\n",
    "        if row == 0.000000 :    \n",
    "            return 'NEU'\n",
    "        elif row > 0.000000:  \n",
    "            return 'POS'\n",
    "        elif row < 0.000000:  \n",
    "            return 'NEG'\n",
    "        else:          \n",
    "            return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "42893ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_emotion_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>lexicon_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "      <td>AnalyzerOutput(output=sadness, probas={sadness...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.936,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.913,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.861,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "134         no_agreement       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...   \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...   \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=NEG, probas={NEG: 0.913,...   \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...   \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...   \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "                              nf_emotion_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=others, probas={others: ...   \n",
       "1    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "2    AnalyzerOutput(output=sadness, probas={sadness...   \n",
       "3    AnalyzerOutput(output=joy, probas={joy: 0.936,...   \n",
       "4    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=others, probas={others: ...   \n",
       "135  AnalyzerOutput(output=others, probas={others: ...   \n",
       "136  AnalyzerOutput(output=joy, probas={joy: 0.861,...   \n",
       "137  AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "138  AnalyzerOutput(output=others, probas={others: ...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            1.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.000000                            0.000000   \n",
       "3                        0.714286                            0.714286   \n",
       "4                        0.000000                            0.000000   \n",
       "..                            ...                                 ...   \n",
       "134                     -1.000000                           -1.000000   \n",
       "135                      0.000000                            0.000000   \n",
       "136                      1.000000                            1.000000   \n",
       "137                      1.000000                            1.000000   \n",
       "138                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected lexicon_emotion  \n",
       "0                          1.000000             joy  \n",
       "1                          0.000000         disgust  \n",
       "2                          0.000000           anger  \n",
       "3                          0.714286             joy  \n",
       "4                          0.000000             joy  \n",
       "..                              ...             ...  \n",
       "134                       -1.000000           anger  \n",
       "135                        0.000000          others  \n",
       "136                        1.000000          others  \n",
       "137                        1.000000          others  \n",
       "138                        1.000000          others  \n",
       "\n",
       "[268 rows x 10 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa19217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\2829403295.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['manual_lexicon_sent_score'] = df['nf_sentiment_lexicon_dispecs'].apply(change_values)\n"
     ]
    }
   ],
   "source": [
    "df['manual_lexicon_sent_score'] = df['nf_sentiment_lexicon_dispecs'].apply(change_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb13a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3244469206.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comp_lexicon_sent_score'] = df['nf_sentiment_lexicon_computational'].apply(change_values)\n"
     ]
    }
   ],
   "source": [
    "df['comp_lexicon_sent_score'] = df['nf_sentiment_lexicon_computational'].apply(change_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "47f68043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\2604159805.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['corr_lexicon_sent_score'] = df['nf_sentiment_lexicon_corrected'].apply(change_values)\n"
     ]
    }
   ],
   "source": [
    "df['corr_lexicon_sent_score'] = df['nf_sentiment_lexicon_corrected'].apply(change_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5631c7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_emotion_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>lexicon_emotion</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "      <td>AnalyzerOutput(output=sadness, probas={sadness...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>anger</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.936,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.913,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>anger</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.861,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "134         no_agreement       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...   \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...   \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=NEG, probas={NEG: 0.913,...   \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...   \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...   \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "                              nf_emotion_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=others, probas={others: ...   \n",
       "1    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "2    AnalyzerOutput(output=sadness, probas={sadness...   \n",
       "3    AnalyzerOutput(output=joy, probas={joy: 0.936,...   \n",
       "4    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=others, probas={others: ...   \n",
       "135  AnalyzerOutput(output=others, probas={others: ...   \n",
       "136  AnalyzerOutput(output=joy, probas={joy: 0.861,...   \n",
       "137  AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "138  AnalyzerOutput(output=others, probas={others: ...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            1.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.000000                            0.000000   \n",
       "3                        0.714286                            0.714286   \n",
       "4                        0.000000                            0.000000   \n",
       "..                            ...                                 ...   \n",
       "134                     -1.000000                           -1.000000   \n",
       "135                      0.000000                            0.000000   \n",
       "136                      1.000000                            1.000000   \n",
       "137                      1.000000                            1.000000   \n",
       "138                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected lexicon_emotion manual_lexicon_sent_score  \\\n",
       "0                          1.000000             joy                       POS   \n",
       "1                          0.000000         disgust                       NEU   \n",
       "2                          0.000000           anger                       NEU   \n",
       "3                          0.714286             joy                       POS   \n",
       "4                          0.000000             joy                       NEU   \n",
       "..                              ...             ...                       ...   \n",
       "134                       -1.000000           anger                       NEG   \n",
       "135                        0.000000          others                       NEU   \n",
       "136                        1.000000          others                       POS   \n",
       "137                        1.000000          others                       POS   \n",
       "138                        1.000000          others                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score  \n",
       "0                       POS                     POS  \n",
       "1                       NEU                     NEU  \n",
       "2                       NEU                     NEU  \n",
       "3                       POS                     POS  \n",
       "4                       NEU                     NEU  \n",
       "..                      ...                     ...  \n",
       "134                     NEG                     NEG  \n",
       "135                     NEU                     NEU  \n",
       "136                     POS                     POS  \n",
       "137                     POS                     POS  \n",
       "138                     POS                     POS  \n",
       "\n",
       "[268 rows x 13 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6361f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nf_sentiment_pysentimiento'] = df['nf_sentiment_pysentimiento'].astype('string')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nf_emotion_pysentimiento'] = df['nf_emotion_pysentimiento'].astype('string')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_py'] = df['nf_sentiment_pysentimiento'].str.findall(r'\\=([^,]+)\\, probas')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['emotion_py'] = df['nf_emotion_pysentimiento'].str.findall(r'\\=([^,]+)\\, probas')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_py'] = df['sentiment_py'].astype('string')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['emotion_py'] = df['emotion_py'].astype('string')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['sentiment_py'] = df['sentiment_py'].str.replace('[', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_py'] = df['sentiment_py'].str.replace('[', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['sentiment_py'] = df['sentiment_py'].str.replace(']', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_py'] = df['sentiment_py'].str.replace(']', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_py'] = df['sentiment_py'].str.replace(\"'\", \"\")\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['emotion_py'] = df['emotion_py'].str.replace('[', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['emotion_py'] = df['emotion_py'].str.replace('[', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['emotion_py'] = df['emotion_py'].str.replace(']', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['emotion_py'] = df['emotion_py'].str.replace(']', '')\n",
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1897579633.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['emotion_py'] = df['emotion_py'].str.replace(\"'\", \"\")\n"
     ]
    }
   ],
   "source": [
    "df['nf_sentiment_pysentimiento'] = df['nf_sentiment_pysentimiento'].astype('string')\n",
    "df['nf_emotion_pysentimiento'] = df['nf_emotion_pysentimiento'].astype('string')\n",
    "df['sentiment_py'] = df['nf_sentiment_pysentimiento'].str.findall(r'\\=([^,]+)\\, probas')\n",
    "df['emotion_py'] = df['nf_emotion_pysentimiento'].str.findall(r'\\=([^,]+)\\, probas')\n",
    "df['sentiment_py'] = df['sentiment_py'].astype('string')\n",
    "df['emotion_py'] = df['emotion_py'].astype('string')\n",
    "df['sentiment_py'] = df['sentiment_py'].str.replace('[', '')\n",
    "df['sentiment_py'] = df['sentiment_py'].str.replace(']', '')\n",
    "df['sentiment_py'] = df['sentiment_py'].str.replace(\"'\", \"\")\n",
    "df['emotion_py'] = df['emotion_py'].str.replace('[', '')\n",
    "df['emotion_py'] = df['emotion_py'].str.replace(']', '')\n",
    "df['emotion_py'] = df['emotion_py'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "765e61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_emotion_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>lexicon_emotion</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "      <th>sentiment_py</th>\n",
       "      <th>emotion_py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "      <td>AnalyzerOutput(output=sadness, probas={sadness...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>anger</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.936,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>G00Q266</td>\n",
       "      <td>Ya he demostrado que el tiempo que se pierde e...</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.913,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>anger</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.861,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "134       G00Q266  Ya he demostrado que el tiempo que se pierde e...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "134         no_agreement       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...   \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...   \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=NEG, probas={NEG: 0.913,...   \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...   \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...   \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "                              nf_emotion_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=others, probas={others: ...   \n",
       "1    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "2    AnalyzerOutput(output=sadness, probas={sadness...   \n",
       "3    AnalyzerOutput(output=joy, probas={joy: 0.936,...   \n",
       "4    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "..                                                 ...   \n",
       "134  AnalyzerOutput(output=others, probas={others: ...   \n",
       "135  AnalyzerOutput(output=others, probas={others: ...   \n",
       "136  AnalyzerOutput(output=joy, probas={joy: 0.861,...   \n",
       "137  AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "138  AnalyzerOutput(output=others, probas={others: ...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            1.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.000000                            0.000000   \n",
       "3                        0.714286                            0.714286   \n",
       "4                        0.000000                            0.000000   \n",
       "..                            ...                                 ...   \n",
       "134                     -1.000000                           -1.000000   \n",
       "135                      0.000000                            0.000000   \n",
       "136                      1.000000                            1.000000   \n",
       "137                      1.000000                            1.000000   \n",
       "138                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected lexicon_emotion manual_lexicon_sent_score  \\\n",
       "0                          1.000000             joy                       POS   \n",
       "1                          0.000000         disgust                       NEU   \n",
       "2                          0.000000           anger                       NEU   \n",
       "3                          0.714286             joy                       POS   \n",
       "4                          0.000000             joy                       NEU   \n",
       "..                              ...             ...                       ...   \n",
       "134                       -1.000000           anger                       NEG   \n",
       "135                        0.000000          others                       NEU   \n",
       "136                        1.000000          others                       POS   \n",
       "137                        1.000000          others                       POS   \n",
       "138                        1.000000          others                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score sentiment_py emotion_py  \n",
       "0                       POS                     POS          NEU     others  \n",
       "1                       NEU                     NEU          NEG      anger  \n",
       "2                       NEU                     NEU          NEG    sadness  \n",
       "3                       POS                     POS          POS        joy  \n",
       "4                       NEU                     NEU          NEG      anger  \n",
       "..                      ...                     ...          ...        ...  \n",
       "134                     NEG                     NEG          NEG     others  \n",
       "135                     NEU                     NEU          NEU     others  \n",
       "136                     POS                     POS          POS        joy  \n",
       "137                     POS                     POS          NEG      anger  \n",
       "138                     POS                     POS          NEG     others  \n",
       "\n",
       "[268 rows x 15 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "140693c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "49f28a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('sentences_sentiment_emotion.pk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b63c58",
   "metadata": {},
   "source": [
    "# Calculating accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61409c87",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d5c9ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c8553",
   "metadata": {},
   "source": [
    "Dropping all rows that have 'no_agreement' in the sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2646cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = df[df[\"sentiment_annotation\"] != 'no_agreement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f12fc4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c869343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there duplicates in the subset?: False\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_sentiment.duplicated(subset=['question_code', 'sentence'], keep=False)\n",
    "\n",
    "# Output True if there are duplicates, False otherwise\n",
    "has_duplicates = any(duplicates)\n",
    "print(\"Are there duplicates in the subset?:\", has_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361be82e",
   "metadata": {},
   "source": [
    "We now have 263 sentences in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "520c273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_emotion_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>lexicon_emotion</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "      <th>sentiment_py</th>\n",
       "      <th>emotion_py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "      <td>AnalyzerOutput(output=sadness, probas={sadness...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>anger</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.936,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>G00Q265</td>\n",
       "      <td>Nos quexamos continuamente de que nuestros dia...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.914,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.861,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "133       G00Q265  Nos quexamos continuamente de que nuestros dia...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "133                  NEG       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...   \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...   \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...   \n",
       "..                                                 ...   \n",
       "133  AnalyzerOutput(output=NEG, probas={NEG: 0.914,...   \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...   \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...   \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "                              nf_emotion_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=others, probas={others: ...   \n",
       "1    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "2    AnalyzerOutput(output=sadness, probas={sadness...   \n",
       "3    AnalyzerOutput(output=joy, probas={joy: 0.936,...   \n",
       "4    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "..                                                 ...   \n",
       "133  AnalyzerOutput(output=others, probas={others: ...   \n",
       "135  AnalyzerOutput(output=others, probas={others: ...   \n",
       "136  AnalyzerOutput(output=joy, probas={joy: 0.861,...   \n",
       "137  AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "138  AnalyzerOutput(output=others, probas={others: ...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            1.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.000000                            0.000000   \n",
       "3                        0.714286                            0.714286   \n",
       "4                        0.000000                            0.000000   \n",
       "..                            ...                                 ...   \n",
       "133                      0.000000                            0.000000   \n",
       "135                      0.000000                            0.000000   \n",
       "136                      1.000000                            1.000000   \n",
       "137                      1.000000                            1.000000   \n",
       "138                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected lexicon_emotion manual_lexicon_sent_score  \\\n",
       "0                          1.000000             joy                       POS   \n",
       "1                          0.000000         disgust                       NEU   \n",
       "2                          0.000000           anger                       NEU   \n",
       "3                          0.714286             joy                       POS   \n",
       "4                          0.000000             joy                       NEU   \n",
       "..                              ...             ...                       ...   \n",
       "133                        0.000000          others                       NEU   \n",
       "135                        0.000000          others                       NEU   \n",
       "136                        1.000000          others                       POS   \n",
       "137                        1.000000          others                       POS   \n",
       "138                        1.000000          others                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score sentiment_py emotion_py  \n",
       "0                       POS                     POS          NEU     others  \n",
       "1                       NEU                     NEU          NEG      anger  \n",
       "2                       NEU                     NEU          NEG    sadness  \n",
       "3                       POS                     POS          POS        joy  \n",
       "4                       NEU                     NEU          NEG      anger  \n",
       "..                      ...                     ...          ...        ...  \n",
       "133                     NEU                     NEU          NEG     others  \n",
       "135                     NEU                     NEU          NEU     others  \n",
       "136                     POS                     POS          POS        joy  \n",
       "137                     POS                     POS          NEG      anger  \n",
       "138                     POS                     POS          NEG     others  \n",
       "\n",
       "[253 rows x 15 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b64979d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1941123642.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['sentiment_annotation_list'] = df_sentiment['sentiment_annotation'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
     ]
    }
   ],
   "source": [
    "df_sentiment['sentiment_annotation_list'] = df_sentiment['sentiment_annotation'].replace(['POS','NEG','NEU'],['1','3','2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d6daf05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3381453953.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['sentiment_py_list'] = df_sentiment['sentiment_py'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
     ]
    }
   ],
   "source": [
    "df_sentiment['sentiment_py_list'] = df_sentiment['sentiment_py'].replace(['POS','NEG','NEU'],['1','3','2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c4965ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1259448734.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['corr_lexicon_sent_score_list'] = df_sentiment['corr_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
     ]
    }
   ],
   "source": [
    "df_sentiment['corr_lexicon_sent_score_list'] = df_sentiment['corr_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c080c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\3731824705.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['manual_lexicon_sent_score_list'] = df_sentiment['manual_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
     ]
    }
   ],
   "source": [
    "df_sentiment['manual_lexicon_sent_score_list'] = df_sentiment['manual_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a637a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\2301282570.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentiment['computational_lexicon_sent_score_list'] = df_sentiment['comp_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
     ]
    }
   ],
   "source": [
    "df_sentiment['computational_lexicon_sent_score_list'] = df_sentiment['comp_lexicon_sent_score'].replace(['POS','NEG','NEU'],['1','3','2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "57194a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_code</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_annotation</th>\n",
       "      <th>emotion_annotation</th>\n",
       "      <th>nf_sentiment_pysentimiento</th>\n",
       "      <th>nf_emotion_pysentimiento</th>\n",
       "      <th>nf_sentiment_lexicon_dispecs</th>\n",
       "      <th>nf_sentiment_lexicon_computational</th>\n",
       "      <th>nf_sentiment_lexicon_corrected</th>\n",
       "      <th>lexicon_emotion</th>\n",
       "      <th>manual_lexicon_sent_score</th>\n",
       "      <th>comp_lexicon_sent_score</th>\n",
       "      <th>corr_lexicon_sent_score</th>\n",
       "      <th>sentiment_py</th>\n",
       "      <th>emotion_py</th>\n",
       "      <th>sentiment_annotation_list</th>\n",
       "      <th>sentiment_py_list</th>\n",
       "      <th>corr_lexicon_sent_score_list</th>\n",
       "      <th>manual_lexicon_sent_score_list</th>\n",
       "      <th>computational_lexicon_sent_score_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G01Q02</td>\n",
       "      <td>Continuamente la oygo decir à sus solas, y mas...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.632,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G01Q03</td>\n",
       "      <td>Matò à un Joven por haver murmurado de la cond...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G01Q04</td>\n",
       "      <td>,Pero no havia pisado sus umbrales, quando la ...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.769,...</td>\n",
       "      <td>AnalyzerOutput(output=sadness, probas={sadness...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>anger</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G01Q05</td>\n",
       "      <td>Su tierno corazon, su espiritu admirable, su m...</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.922,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.936,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>joy</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G01Q06</td>\n",
       "      <td>Otra Señorita, hermosa por extremo, garbosa de...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.773,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>G00Q265</td>\n",
       "      <td>Nos quexamos continuamente de que nuestros dia...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.914,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEG</td>\n",
       "      <td>others</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>G00Q267</td>\n",
       "      <td>Los dos sexôs, y todos los estados de la repúb...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>disgust</td>\n",
       "      <td>AnalyzerOutput(output=NEU, probas={NEU: 0.524,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "      <td>others</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>G00Q268</td>\n",
       "      <td>aplaude la buena educacion Francesa;</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=POS, probas={POS: 0.846,...</td>\n",
       "      <td>AnalyzerOutput(output=joy, probas={joy: 0.861,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>G00Q269</td>\n",
       "      <td>Si vmd. ama mas las alabanzas que el mérito, a...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.845,...</td>\n",
       "      <td>AnalyzerOutput(output=anger, probas={anger: 0....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>G00Q270</td>\n",
       "      <td>Es gallardo jóven, tiene los ojos mas negros, ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>no_agreement</td>\n",
       "      <td>AnalyzerOutput(output=NEG, probas={NEG: 0.782,...</td>\n",
       "      <td>AnalyzerOutput(output=others, probas={others: ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>others</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEG</td>\n",
       "      <td>others</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_code                                           sentence  \\\n",
       "0          G01Q02  Continuamente la oygo decir à sus solas, y mas...   \n",
       "1          G01Q03  Matò à un Joven por haver murmurado de la cond...   \n",
       "2          G01Q04  ,Pero no havia pisado sus umbrales, quando la ...   \n",
       "3          G01Q05  Su tierno corazon, su espiritu admirable, su m...   \n",
       "4          G01Q06  Otra Señorita, hermosa por extremo, garbosa de...   \n",
       "..            ...                                                ...   \n",
       "133       G00Q265  Nos quexamos continuamente de que nuestros dia...   \n",
       "135       G00Q267  Los dos sexôs, y todos los estados de la repúb...   \n",
       "136       G00Q268               aplaude la buena educacion Francesa;   \n",
       "137       G00Q269  Si vmd. ama mas las alabanzas que el mérito, a...   \n",
       "138       G00Q270  Es gallardo jóven, tiene los ojos mas negros, ...   \n",
       "\n",
       "    sentiment_annotation emotion_annotation  \\\n",
       "0                    NEU       no_agreement   \n",
       "1                    NEG            disgust   \n",
       "2                    NEU      no_agreement    \n",
       "3                    POS                joy   \n",
       "4                    NEG       no_agreement   \n",
       "..                   ...                ...   \n",
       "133                  NEG       no_agreement   \n",
       "135                  NEG            disgust   \n",
       "136                  POS       no_agreement   \n",
       "137                  NEU         no_emotion   \n",
       "138                  POS       no_agreement   \n",
       "\n",
       "                            nf_sentiment_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=NEU, probas={NEU: 0.632,...   \n",
       "1    AnalyzerOutput(output=NEG, probas={NEG: 0.922,...   \n",
       "2    AnalyzerOutput(output=NEG, probas={NEG: 0.769,...   \n",
       "3    AnalyzerOutput(output=POS, probas={POS: 0.922,...   \n",
       "4    AnalyzerOutput(output=NEG, probas={NEG: 0.773,...   \n",
       "..                                                 ...   \n",
       "133  AnalyzerOutput(output=NEG, probas={NEG: 0.914,...   \n",
       "135  AnalyzerOutput(output=NEU, probas={NEU: 0.524,...   \n",
       "136  AnalyzerOutput(output=POS, probas={POS: 0.846,...   \n",
       "137  AnalyzerOutput(output=NEG, probas={NEG: 0.845,...   \n",
       "138  AnalyzerOutput(output=NEG, probas={NEG: 0.782,...   \n",
       "\n",
       "                              nf_emotion_pysentimiento  \\\n",
       "0    AnalyzerOutput(output=others, probas={others: ...   \n",
       "1    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "2    AnalyzerOutput(output=sadness, probas={sadness...   \n",
       "3    AnalyzerOutput(output=joy, probas={joy: 0.936,...   \n",
       "4    AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "..                                                 ...   \n",
       "133  AnalyzerOutput(output=others, probas={others: ...   \n",
       "135  AnalyzerOutput(output=others, probas={others: ...   \n",
       "136  AnalyzerOutput(output=joy, probas={joy: 0.861,...   \n",
       "137  AnalyzerOutput(output=anger, probas={anger: 0....   \n",
       "138  AnalyzerOutput(output=others, probas={others: ...   \n",
       "\n",
       "     nf_sentiment_lexicon_dispecs  nf_sentiment_lexicon_computational  \\\n",
       "0                        1.000000                            1.000000   \n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.000000                            0.000000   \n",
       "3                        0.714286                            0.714286   \n",
       "4                        0.000000                            0.000000   \n",
       "..                            ...                                 ...   \n",
       "133                      0.000000                            0.000000   \n",
       "135                      0.000000                            0.000000   \n",
       "136                      1.000000                            1.000000   \n",
       "137                      1.000000                            1.000000   \n",
       "138                      1.000000                            1.000000   \n",
       "\n",
       "     nf_sentiment_lexicon_corrected lexicon_emotion manual_lexicon_sent_score  \\\n",
       "0                          1.000000             joy                       POS   \n",
       "1                          0.000000         disgust                       NEU   \n",
       "2                          0.000000           anger                       NEU   \n",
       "3                          0.714286             joy                       POS   \n",
       "4                          0.000000             joy                       NEU   \n",
       "..                              ...             ...                       ...   \n",
       "133                        0.000000          others                       NEU   \n",
       "135                        0.000000          others                       NEU   \n",
       "136                        1.000000          others                       POS   \n",
       "137                        1.000000          others                       POS   \n",
       "138                        1.000000          others                       POS   \n",
       "\n",
       "    comp_lexicon_sent_score corr_lexicon_sent_score sentiment_py emotion_py  \\\n",
       "0                       POS                     POS          NEU     others   \n",
       "1                       NEU                     NEU          NEG      anger   \n",
       "2                       NEU                     NEU          NEG    sadness   \n",
       "3                       POS                     POS          POS        joy   \n",
       "4                       NEU                     NEU          NEG      anger   \n",
       "..                      ...                     ...          ...        ...   \n",
       "133                     NEU                     NEU          NEG     others   \n",
       "135                     NEU                     NEU          NEU     others   \n",
       "136                     POS                     POS          POS        joy   \n",
       "137                     POS                     POS          NEG      anger   \n",
       "138                     POS                     POS          NEG     others   \n",
       "\n",
       "    sentiment_annotation_list sentiment_py_list corr_lexicon_sent_score_list  \\\n",
       "0                           2                 2                            1   \n",
       "1                           3                 3                            2   \n",
       "2                           2                 3                            2   \n",
       "3                           1                 1                            1   \n",
       "4                           3                 3                            2   \n",
       "..                        ...               ...                          ...   \n",
       "133                         3                 3                            2   \n",
       "135                         3                 2                            2   \n",
       "136                         1                 1                            1   \n",
       "137                         2                 3                            1   \n",
       "138                         1                 3                            1   \n",
       "\n",
       "    manual_lexicon_sent_score_list computational_lexicon_sent_score_list  \n",
       "0                                1                                     1  \n",
       "1                                2                                     2  \n",
       "2                                2                                     2  \n",
       "3                                1                                     1  \n",
       "4                                2                                     2  \n",
       "..                             ...                                   ...  \n",
       "133                              2                                     2  \n",
       "135                              2                                     2  \n",
       "136                              1                                     1  \n",
       "137                              1                                     1  \n",
       "138                              1                                     1  \n",
       "\n",
       "[253 rows x 20 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e2920e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c867a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '2', '1', '3', '3', '3', '3', '3', '3', '3', '2', '3', '1', '3', '3', '2', '1', '1', '1', '1', '2', '3', '3', '3', '1', '3', '2', '3', '2', '1', '3', '1', '2', '3', '3', '1', '1', '3', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '1', '3', '3', '1', '1', '3', '1', '1', '1', '3', '3', '3', '3', '2', '3', '2', '2', '3', '2', '1', '2', '2', '3', '1', '3', '3', '3', '3', '3', '3', '3', '2', '2', '2', '1', '3', '2', '3', '3', '3', '3', '3', '3', '3', '1', '2', '3', '3', '2', '1', '3', '1', '3', '3', '2', '3', '2', '3', '2', '3', '3', '1', '3', '3', '3', '3', '3', '2', '3', '1', '1', '3', '3', '3', '3', '3', '2', '1', '1', '3', '2', '3', '3', '3', '3', '3', '1', '2', '1', '3', '2', '3', '2', '2', '2', '3', '2', '2', '3', '3', '3', '3', '1', '3', '1', '3', '2', '3', '1', '3', '3', '3', '1', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '1', '1', '1', '3', '3', '3', '1', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '1', '3', '3', '2', '1', '3', '3', '3', '1', '3', '1', '3', '1', '3', '3', '1', '1', '3', '3', '3', '2', '2', '3', '1', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3', '1', '1', '2', '3', '3', '2', '3', '2', '1', '1', '2', '1', '1', '1', '3', '1', '3', '1', '3', '3', '3', '1', '2', '1']\n"
     ]
    }
   ],
   "source": [
    "sentiment_annotation_list = df_sentiment['sentiment_annotation_list'].tolist()\n",
    "print(sentiment_annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fd4f360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '3', '1', '3', '2', '3', '3', '3', '3', '1', '2', '3', '1', '3', '3', '2', '2', '1', '3', '3', '3', '2', '3', '3', '1', '3', '3', '2', '1', '1', '3', '2', '2', '2', '3', '1', '2', '3', '2', '3', '2', '3', '2', '2', '2', '3', '3', '2', '3', '1', '3', '3', '2', '1', '3', '2', '3', '2', '3', '3', '3', '3', '3', '2', '2', '2', '3', '2', '1', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '1', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '2', '2', '3', '2', '3', '2', '3', '3', '1', '1', '3', '2', '2', '2', '2', '3', '3', '2', '2', '1', '3', '3', '3', '2', '3', '2', '2', '2', '1', '3', '3', '3', '3', '1', '3', '1', '2', '3', '3', '3', '1', '3', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '1', '2', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '3', '3', '3', '1', '1', '2', '3', '3', '3', '3', '1', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '2', '1', '2', '3', '2', '3', '3', '3', '1', '1', '2', '1', '2', '3', '3', '2', '3', '1', '2', '3', '2', '1', '3', '3']\n"
     ]
    }
   ],
   "source": [
    "sentiment_py_list = df_sentiment['sentiment_py_list'].tolist()\n",
    "print(sentiment_py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "70e0ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '2', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '3', '2', '1', '1', '2', '3', '2', '2', '1', '1', '1', '2', '1', '3', '2', '1', '3', '2', '2', '3', '3', '1', '1', '3', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '3', '2', '2', '1', '1', '1', '2', '3', '3', '3', '3', '1', '1', '1', '1', '1', '3', '2', '1', '1', '1', '3', '1', '3', '1', '3', '3', '2', '3', '3', '3', '1', '1', '1', '1', '2', '3', '3', '3', '1', '3', '1', '2', '1', '2', '1', '1', '1', '3', '2', '1', '2', '3', '1', '1', '1', '2', '3', '1', '3', '2', '1', '2', '1', '1', '2', '1', '1', '2', '2', '3', '3', '1', '1', '2', '1', '1', '1', '3', '1', '3', '2', '2', '2', '2', '1', '2', '1', '3', '2', '3', '1', '1', '1', '1', '2', '1', '3', '3', '3', '3', '1', '1', '1', '2', '2', '1', '1', '1', '3', '2', '1', '1', '2', '2', '3', '2', '3', '3', '3', '1', '3', '2', '1', '1', '1', '3', '3', '3', '3', '1', '3', '1', '1', '2', '3', '2', '2', '1', '1', '1', '3', '1', '1', '1', '2', '1', '1', '1', '1', '2', '3', '1', '1', '1', '2', '2', '3', '2', '2', '3', '1', '1', '3', '3', '2', '3', '3', '3', '3', '3', '2', '1', '2', '1', '2', '2', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "corr_lexicon_sent_score_list = df_sentiment['corr_lexicon_sent_score_list'].tolist()\n",
    "print(corr_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4ddf228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '2', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '3', '2', '1', '1', '2', '3', '2', '2', '1', '1', '1', '2', '1', '3', '2', '1', '3', '2', '2', '3', '3', '1', '1', '3', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '3', '2', '2', '1', '1', '1', '2', '3', '3', '3', '3', '1', '1', '1', '1', '1', '3', '2', '1', '1', '1', '3', '1', '3', '1', '3', '3', '2', '3', '3', '3', '1', '1', '1', '1', '2', '3', '3', '3', '1', '3', '1', '2', '1', '2', '1', '1', '1', '3', '2', '1', '2', '3', '1', '1', '1', '2', '3', '1', '3', '2', '1', '2', '1', '1', '2', '1', '1', '2', '2', '3', '3', '1', '1', '2', '1', '1', '1', '3', '1', '3', '2', '2', '2', '2', '1', '2', '1', '3', '2', '3', '1', '1', '1', '1', '2', '1', '3', '3', '3', '3', '1', '1', '1', '2', '2', '1', '1', '1', '3', '2', '1', '1', '2', '2', '3', '2', '3', '3', '3', '1', '3', '2', '1', '1', '1', '3', '3', '3', '3', '1', '3', '1', '1', '2', '3', '2', '2', '1', '1', '1', '3', '1', '1', '1', '2', '1', '1', '1', '1', '2', '3', '1', '1', '1', '2', '2', '3', '2', '2', '3', '1', '1', '3', '3', '2', '3', '3', '3', '3', '3', '2', '1', '2', '1', '2', '2', '3', '1', '1', '3', '3', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "manual_lexicon_sent_score_list = df_sentiment['manual_lexicon_sent_score_list'].tolist()\n",
    "print(manual_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dee72c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '2', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '2', '3', '1', '1', '1', '2', '3', '2', '2', '1', '1', '1', '2', '1', '2', '2', '1', '3', '1', '2', '3', '3', '1', '1', '3', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '3', '1', '2', '1', '1', '1', '2', '3', '3', '3', '3', '1', '1', '1', '1', '1', '3', '2', '1', '1', '1', '3', '2', '3', '1', '3', '3', '2', '3', '2', '3', '1', '1', '1', '1', '2', '3', '3', '3', '1', '3', '1', '1', '1', '2', '1', '1', '1', '3', '1', '1', '2', '3', '1', '1', '1', '2', '3', '1', '3', '2', '1', '3', '1', '1', '1', '1', '1', '2', '2', '3', '3', '1', '1', '2', '1', '1', '1', '1', '1', '3', '2', '2', '2', '2', '1', '2', '1', '3', '2', '3', '1', '1', '1', '1', '1', '1', '3', '3', '3', '2', '1', '1', '1', '2', '1', '1', '1', '2', '2', '2', '1', '1', '2', '2', '3', '2', '3', '3', '3', '1', '1', '1', '1', '1', '1', '3', '3', '2', '3', '2', '3', '1', '1', '2', '3', '2', '2', '1', '1', '1', '3', '2', '1', '1', '2', '1', '1', '1', '1', '1', '3', '1', '1', '1', '1', '2', '3', '2', '2', '3', '1', '1', '3', '3', '2', '3', '3', '2', '3', '1', '2', '1', '1', '1', '2', '2', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "computational_lexicon_sent_score_list = df_sentiment['computational_lexicon_sent_score_list'].tolist()\n",
    "print(computational_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1bf83",
   "metadata": {},
   "source": [
    "## Pysentimiento sentiment accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2847f011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640316205533597"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,sentiment_py_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f526e",
   "metadata": {},
   "source": [
    "Pysentimiento has ok accuracy - 60% - https://stephenallwright.com/good-accuracy-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c6c8c573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,sentiment_py_list, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d978c351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.46      0.57        57\n",
      "           2       0.40      0.42      0.41        55\n",
      "           3       0.74      0.84      0.79       141\n",
      "\n",
      "    accuracy                           0.66       253\n",
      "   macro avg       0.63      0.57      0.59       253\n",
      "weighted avg       0.67      0.66      0.66       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(sentiment_annotation_list, sentiment_py_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d3e7e",
   "metadata": {},
   "source": [
    "Recall: out of all the sentences that the model predicted, 76% match the test set. F1 shows that the model did a OK job (77%) of predicting the sentiment. Precision - measure how many of the positive predictions made are correct, recall - how many of the positive cases the classifier correctly predicred over all the pos cases - https://www.statology.org/sklearn-classification-report/, https://stephenallwright.com/interpret-f1-score/, https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0c9f90a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,  17,  14],\n",
       "       [  4,  23,  28],\n",
       "       [  4,  18, 119]], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(sentiment_annotation_list, sentiment_py_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7ff41",
   "metadata": {},
   "source": [
    "## Corrected lexicon sentiment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "512e12dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43873517786561267"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sentiment_annotation_list,corr_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "14141934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.74      0.47        57\n",
      "           2       0.26      0.31      0.28        55\n",
      "           3       0.80      0.37      0.50       141\n",
      "\n",
      "    accuracy                           0.44       253\n",
      "   macro avg       0.47      0.47      0.42       253\n",
      "weighted avg       0.58      0.44      0.45       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_annotation_list, corr_lexicon_sent_score_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f14ff7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f89b2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_matrix = confusion_matrix(sentiment_annotation_list, corr_lexicon_sent_score_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fdc3ae58",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‘' (U+2018) (1074823236.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\krusic\\AppData\\Local\\Temp\\ipykernel_29844\\1074823236.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    labels = [‘True Neg’,’False Pos’,’False Neg’,’True Pos’]\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '‘' (U+2018)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = [‘True Neg’,’False Pos’,’False Neg’,’True Pos’]\n",
    "categories = [‘Zero’, ‘One’]\n",
    "make_confusion_matrix(lexicon_matrix, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap=’binary’)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12954d",
   "metadata": {},
   "source": [
    "# Manual lexicon sentiment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(sentiment_annotation_list,manual_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(sentiment_annotation_list, manual_lexicon_sent_score_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c32fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(sentiment_annotation_list, manual_lexicon_sent_score_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce193eb0",
   "metadata": {},
   "source": [
    "## Computational lexicon sentiment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da15a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(sentiment_annotation_list,computational_lexicon_sent_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(sentiment_annotation_list, computational_lexicon_sent_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(sentiment_annotation_list, computational_lexicon_sent_score_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd98393",
   "metadata": {},
   "source": [
    "# Emotion lexicon evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_annotation'] = df['emotion_annotation'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14966fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = df[df[\"emotion_annotation\"] != 'no_agreement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = df_emotion[df_emotion[\"emotion_annotation\"] != 'anticipation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = df_emotion[df_emotion[\"emotion_annotation\"] != 'trust']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed12608",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766172c",
   "metadata": {},
   "source": [
    "joy - 1\n",
    "sadness - 2\n",
    "anger - 3\n",
    "disgust - 4\n",
    "surprise - 5\n",
    "fear - 6 \n",
    "no_emotion(others) - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['emotion_annotation_list'] = df_emotion['emotion_annotation'].replace(['joy','sadness','anger','disgust','surprise','fear','no_emotion'],['1','2','3','4','5','6','7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_annotation_list = df_emotion['emotion_annotation_list'].tolist()\n",
    "print(emotion_annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['emotion_py_list'] = df_emotion['emotion_py'].replace(['joy','sadness','anger','disgust','surprise','fear','others'],['1','2','3','4','5','6','7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca14f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_py_list = df_emotion['emotion_py_list'].tolist()\n",
    "print(emotion_py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['emotion_lexicon_list'] = df_emotion['lexicon_emotion'].replace(['joy','sadness','anger','disgust','surprise','fear','others'],['1','2','3','4','5','6','7'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14064e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_lexicon_list = df_emotion['emotion_lexicon_list'].tolist()\n",
    "print(emotion_lexicon_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffebb8",
   "metadata": {},
   "source": [
    "# Emotion Lexicon accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3614557",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(emotion_annotation_list,emotion_lexicon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ed29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(emotion_annotation_list,emotion_lexicon_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69695c5",
   "metadata": {},
   "source": [
    "# Pysentimiento emotion accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(emotion_annotation_list,emotion_py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc202855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(emotion_annotation_list,emotion_py_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355e17a",
   "metadata": {},
   "source": [
    "Saving the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f12e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
